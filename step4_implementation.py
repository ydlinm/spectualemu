# -*- coding: utf-8 -*-
"""
Step 4: Data Factory (Batch Generation Pipeline)
æ•°æ®å·¥å‚ï¼šæ‰¹é‡ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®é›†
"""

import sys
import io
if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.ndimage import gaussian_filter, rotate, shift
from PIL import Image
import os
from datetime import datetime
import json
from tqdm import tqdm

# ================================
# 1. åŠ è½½ SpectralAssets (å¤ç”¨ step3)
# ================================

class SpectralAssets:
    """å…‰è°±èµ„äº§å®¹å™¨ (Step 1 æ ‡å‡†åŒ–æ•°æ®)"""
    def __init__(self, csv_path):
        df = pd.read_csv(csv_path)
        self.wavelengths = df['wavelength_nm'].values
        self.halogen_spectrum = df['halogen_spectrum'].values
        self.sensor_qe = df['sensor_qe'].values
        self.water_mu_a = df['water_mu_a'].values
        self.lipid_mu_a = df['lipid_mu_a'].values
        self.sebum_mu_a = df['sebum_mu_a'].values
        self.scatter_mus = df['scatter_mus'].values
        self.melanin_mu_a = df['melanin_mu_a'].values
        self.prism_shift_px = df['prism_shift_px'].values
        
        self.num_wavelengths = len(self.wavelengths)
        print(f"âœ“ åŠ è½½å…‰è°±èµ„äº§: {self.num_wavelengths} æ³¢é•¿")


# ================================
# 2. Perlin Noise ç”Ÿæˆå™¨ (çº¹ç†ç”Ÿæˆ)
# ================================

class PerlinNoiseGenerator:
    """Perlin å™ªå£°ç”Ÿæˆå™¨ (ç”¨äºç©ºé—´çº¹ç†å¢å¼º)"""
    
    @staticmethod
    def generate_perlin_2d(shape, scale=50, octaves=4, persistence=0.5, seed=None):
        """
        ç”Ÿæˆ 2D Perlin å™ªå£°
        Args:
            shape: (H, W) è¾“å‡ºå°ºå¯¸
            scale: å™ªå£°é¢‘ç‡ (è¶Šå°è¶Šå¹³æ»‘)
            octaves: å åŠ å±‚æ•° (è¶Šå¤šç»†èŠ‚è¶Šä¸°å¯Œ)
            persistence: æŒ¯å¹…è¡°å‡ç³»æ•°
            seed: éšæœºç§å­
        Returns:
            noise: å½’ä¸€åŒ–åˆ° [0, 1] çš„ 2D æ•°ç»„
        """
        if seed is not None:
            np.random.seed(seed)
        
        H, W = shape
        noise = np.zeros((H, W))
        
        for octave in range(octaves):
            freq = 2 ** octave
            amp = persistence ** octave
            
            # ç”Ÿæˆéšæœºæ¢¯åº¦ç½‘æ ¼
            grid_h = H // (scale // freq) + 2
            grid_w = W // (scale // freq) + 2
            gradients = np.random.randn(grid_h, grid_w, 2)
            
            # ç®€åŒ–ç‰ˆ Perlinï¼ˆä½¿ç”¨é«˜æ–¯å¹³æ»‘æ¨¡æ‹Ÿï¼‰
            layer = np.random.randn(H, W)
            layer = gaussian_filter(layer, sigma=scale / freq)
            noise += amp * layer
        
        # å½’ä¸€åŒ–åˆ° [0, 1]
        noise = (noise - noise.min()) / (noise.max() - noise.min() + 1e-10)
        return noise


# ================================
# 3. Data Factory (æ ¸å¿ƒç±»)
# ================================

class DataFactory:
    """
    æ•°æ®å·¥å‚ï¼šæ‰¹é‡ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®
    """
    
    def __init__(self, assets_path, image_size=256, output_dir='output/datasets'):
        """
        Args:
            assets_path: step1 çš„æ ‡å‡†åŒ–æ•°æ®è·¯å¾„ (CSV)
            image_size: å›¾åƒåˆ†è¾¨ç‡ (åƒç´ )
            output_dir: æ•°æ®é›†è¾“å‡ºç›®å½•
        """
        self.assets = SpectralAssets(assets_path)
        self.image_size = image_size
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # åŠ è½½çº¹ç† (å¦‚æœä¸å­˜åœ¨ï¼Œç”Ÿæˆéšæœºçº¹ç†)
        texture_path = 'assets/skin_texture.png'
        if os.path.exists(texture_path):
            texture = np.array(Image.open(texture_path).convert('L'))
            # è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
            texture = np.array(Image.fromarray(texture).resize((image_size, image_size)))
        else:
            print(f"âš  çº¹ç†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç”Ÿæˆéšæœºçº¹ç†")
            texture = PerlinNoiseGenerator.generate_perlin_2d(
                (image_size, image_size), scale=20, octaves=6
            )
            texture = (texture * 255).astype(np.uint8)
        
        self.base_texture = texture / 255.0  # å½’ä¸€åŒ–åˆ° [0, 1]
        print(f"âœ“ æ•°æ®å·¥å‚åˆå§‹åŒ–å®Œæˆ (å›¾åƒå°ºå¯¸: {image_size}Ã—{image_size})")
    
    def augment_texture(self, seed=None):
        """
        çº¹ç†å¢å¼ºï¼šéšæœºæ—‹è½¬ã€ç¿»è½¬ã€å¹³ç§»
        Returns:
            augmented_texture: (H, W) å½’ä¸€åŒ–çº¹ç†
        """
        if seed is not None:
            np.random.seed(seed)
        
        texture = self.base_texture.copy()
        
        # éšæœºæ—‹è½¬
        angle = np.random.uniform(-180, 180)
        texture = rotate(texture, angle, reshape=False, mode='wrap')
        
        # éšæœºç¿»è½¬
        if np.random.rand() > 0.5:
            texture = np.fliplr(texture)
        if np.random.rand() > 0.5:
            texture = np.flipud(texture)
        
        # éšæœºå¹³ç§»
        shift_x = np.random.randint(-20, 20)
        shift_y = np.random.randint(-20, 20)
        texture = shift(texture, (shift_y, shift_x), mode='wrap')
        
        return texture
    
    def generate_concentration_maps(self, conc_water, conc_sebum, conc_melanin, seed=None):
        """
        ç”Ÿæˆæµ“åº¦ç©ºé—´åˆ†å¸ƒå›¾
        Args:
            conc_water: æ°´æµ“åº¦åŸºå‡†å€¼
            conc_sebum: çš®è„‚æµ“åº¦åŸºå‡†å€¼
            conc_melanin: é»‘è‰²ç´ æµ“åº¦åŸºå‡†å€¼
            seed: éšæœºç§å­
        Returns:
            map_water: (H, W) æ°´æµ“åº¦åˆ†å¸ƒ
            map_sebum: (H, W) çš®è„‚æµ“åº¦åˆ†å¸ƒ
            map_melanin: (H, W) é»‘è‰²ç´ æµ“åº¦åˆ†å¸ƒ
        """
        if seed is not None:
            np.random.seed(seed)
        
        H, W = self.image_size, self.image_size
        
        # æ°´åˆ†å¸ƒï¼šä½é¢‘ Perlin å™ªå£° (æ°´åˆä½œç”¨ç¼“æ…¢å˜åŒ–)
        perlin_water = PerlinNoiseGenerator.generate_perlin_2d(
            (H, W), scale=80, octaves=3, seed=seed
        )
        # è°ƒåˆ¶èŒƒå›´: Â±20% å˜åŒ–
        map_water = conc_water * (0.8 + 0.4 * perlin_water)
        
        # çš®è„‚åˆ†å¸ƒï¼šé«˜é¢‘çº¹ç† (çš®è„‚è·Ÿéšæ¯›å­”/çº¹ç†)
        augmented_texture = self.augment_texture(seed=seed + 1 if seed else None)
        # è°ƒåˆ¶èŒƒå›´: Â±30% å˜åŒ–
        map_sebum = conc_sebum * (0.7 + 0.6 * augmented_texture)
        
        # é»‘è‰²ç´ åˆ†å¸ƒï¼šä¸­é¢‘å™ªå£° (è‰²ç´ æ²‰ç€)
        perlin_melanin = PerlinNoiseGenerator.generate_perlin_2d(
            (H, W), scale=50, octaves=4, seed=seed + 2 if seed else None
        )
        map_melanin = conc_melanin * (0.9 + 0.2 * perlin_melanin)
        
        # ç‰©ç†çº¦æŸï¼šæ€»æµ“åº¦ <= 1.0
        total_map = map_water + map_sebum + map_melanin
        overflow_mask = total_map > 1.0
        if np.any(overflow_mask):
            # å½’ä¸€åŒ–åˆ° 1.0
            scale_factor = 1.0 / total_map[overflow_mask]
            map_water[overflow_mask] *= scale_factor
            map_sebum[overflow_mask] *= scale_factor
            map_melanin[overflow_mask] *= scale_factor
        
        return map_water, map_sebum, map_melanin
    
    def compute_effective_mu_a(self, map_water, map_sebum, map_melanin):
        """
        è®¡ç®—æœ‰æ•ˆå¸æ”¶ç³»æ•° Î¼_a(Î», x, y)
        Args:
            map_water: (H, W) æ°´æµ“åº¦åˆ†å¸ƒ
            map_sebum: (H, W) çš®è„‚æµ“åº¦åˆ†å¸ƒ
            map_melanin: (H, W) é»‘è‰²ç´ æµ“åº¦åˆ†å¸ƒ
        Returns:
            mu_a_map: (H, W, num_wavelengths) æœ‰æ•ˆå¸æ”¶ç³»æ•°
        """
        H, W = map_water.shape
        num_wl = self.assets.num_wavelengths
        
        # æ‰©å±•æ³¢é•¿ç»´åº¦
        mu_a_water_3d = self.assets.water_mu_a[None, None, :]  # (1, 1, num_wl)
        mu_a_sebum_3d = self.assets.sebum_mu_a[None, None, :]
        mu_a_melanin_3d = self.assets.melanin_mu_a[None, None, :]
        
        # æµ“åº¦å›¾æ‰©å±•ç»´åº¦
        map_water_3d = map_water[:, :, None]  # (H, W, 1)
        map_sebum_3d = map_sebum[:, :, None]
        map_melanin_3d = map_melanin[:, :, None]
        
        # çº¿æ€§æ··åˆ
        mu_a_map = (map_water_3d * mu_a_water_3d +
                    map_sebum_3d * mu_a_sebum_3d +
                    map_melanin_3d * mu_a_melanin_3d)
        
        return mu_a_map  # (H, W, num_wl)
    
    def compute_wavelength_dependent_pathlength(self):
        """
        è®¡ç®—æ³¢é•¿ä¾èµ–çš„æœ‰æ•ˆå…‰ç¨‹ d_eff(Î»)
        ç‰©ç†åŸç†ï¼šçŸ­æ³¢æ•£å°„å¼ºï¼Œç©¿é€æµ…ï¼›é•¿æ³¢ç©¿é€æ·±
        
        Returns:
            d_eff_array: (num_wl,) æœ‰æ•ˆå…‰ç¨‹æ•°ç»„ (mm)
        """
        # çº¿æ€§æ¨¡å‹: d_eff(Î») = d_min + (d_max - d_min) * (Î» - Î»_min) / (Î»_max - Î»_min)
        wl = self.assets.wavelengths
        wl_min, wl_max = wl[0], wl[-1]
        d_min, d_max = 0.4, 0.8  # 900nm: 0.4mm, 1700nm: 0.8mm
        
        d_eff_array = d_min + (d_max - d_min) * (wl - wl_min) / (wl_max - wl_min)
        return d_eff_array
    
    def forward_simulation(self, mu_a_map, exposure_factor=1.0, snr_mode='high'):
        """
        æ­£å‘æ¨¡æ‹Ÿï¼šStep2 (å…‰åœº) + Step3 (æ£±é•œ+ä¼ æ„Ÿå™¨)
        æ”¹è¿›ç‰ˆï¼šæ³¢é•¿ä¾èµ–å…‰ç¨‹ + æé«˜å…‰å¼º + SNR å¤šæ ·æ€§
        
        Args:
            mu_a_map: (H, W, num_wl) æœ‰æ•ˆå¸æ”¶ç³»æ•°
            exposure_factor: æ›å…‰æ—¶é—´å› å­ (éšæœºåŒ–ç…§æ˜å¼ºåº¦)
            snr_mode: 'high' (å®éªŒå®¤), 'medium' (æ­£å¸¸), 'low' (æ‰‹æŒæŠ–åŠ¨)
        Returns:
            sensor_image: (H, W) ä¼ æ„Ÿå™¨ ADU å›¾åƒ
            hypercube: (H, W, num_wl) åœºæ™¯è¶…ç«‹æ–¹ä½“
        """
        H, W, num_wl = mu_a_map.shape
        
        # Step 2: ç”Ÿæˆåœºæ™¯è¶…ç«‹æ–¹ä½“ (æ³¢é•¿ä¾èµ–å…‰ä¼ è¾“)
        # åå°„ç‡ R(Î») = exp(-Î¼_a * d_eff(Î»))
        d_eff_array = self.compute_wavelength_dependent_pathlength()  # (num_wl,)
        d_eff_3d = d_eff_array[None, None, :]  # (1, 1, num_wl)
        reflectance = np.exp(-mu_a_map * d_eff_3d)
        
        # ç…§æ˜ Ã— åå°„ç‡ Ã— åŸºå‡†å…‰å¼ºå¢ç›Š (æé«˜200å€åˆ°ä¼ æ„Ÿå™¨æœ€ä½³å·¥ä½œåŒº)
        BASE_GAIN = 200.0  # å…³é”®ä¿®æ­£ï¼šå°†ä¿¡å·æå‡åˆ° 10k-30k ADU åŒºé—´
        illumination = self.assets.halogen_spectrum[None, None, :]  # (1, 1, num_wl)
        hypercube = reflectance * illumination * exposure_factor * BASE_GAIN
        
        # Step 3: ä¼ æ„Ÿå™¨å“åº” + è‰²æ•£
        sensor_qe = self.assets.sensor_qe[None, None, :]  # (1, 1, num_wl)
        photon_flux = hypercube * sensor_qe
        
        # è‰²æ•£æ¨¡æ‹Ÿ (ç®€åŒ–ä¸ºæ³¢é•¿ç§¯åˆ† + æ°´å¹³åç§»)
        sensor_image = np.zeros((H, W), dtype=np.float32)
        prism_shifts = self.assets.prism_shift_px
        
        for wl_idx in range(num_wl):
            shift_px = prism_shifts[wl_idx]
            # æ°´å¹³åç§»
            shifted = shift(photon_flux[:, :, wl_idx], (0, shift_px), mode='constant', cval=0)
            sensor_image += shifted
        
        # å™ªå£°æ¨¡å‹ï¼šæ ¹æ® SNR æ¨¡å¼è°ƒæ•´å™ªå£°æ°´å¹³
        if snr_mode == 'high':  # å®éªŒå®¤ç†æƒ³ç¯å¢ƒ
            read_noise_std = 3.0
            dark_current = 2.0
        elif snr_mode == 'medium':  # æ­£å¸¸ç¯å¢ƒ
            read_noise_std = 5.0
            dark_current = 5.0
        else:  # 'low' - æ‰‹æŒæŠ–åŠ¨/çŸ­æ›å…‰
            read_noise_std = 8.0
            dark_current = 10.0
        
        # æ³Šæ¾å™ªå£° + è¯»å‡ºå™ªå£° + æš—ç”µæµ
        sensor_image = np.clip(sensor_image, 0, None)
        photon_noise = np.random.poisson(sensor_image + 1e-6)
        read_noise = np.random.normal(0, read_noise_std, (H, W))
        dark_current_noise = np.random.poisson(dark_current, (H, W))
        sensor_image_adu = photon_noise + read_noise + dark_current_noise
        
        # é‡åŒ–åˆ° uint16
        sensor_image_adu = np.clip(sensor_image_adu, 0, 65535).astype(np.uint16)
        
        return sensor_image_adu, hypercube
    
    def generate_batch(self, num_samples=100, seed_offset=0):
        """
        æ‰¹é‡ç”Ÿæˆæ•°æ®é›†
        Args:
            num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
            seed_offset: éšæœºç§å­åç§»
        """
        print(f"\nğŸ­ å¯åŠ¨æ•°æ®å·¥å‚ï¼šç”Ÿæˆ {num_samples} ä¸ªè®­ç»ƒæ ·æœ¬...")
        
        metadata_list = []
        
        for i in tqdm(range(num_samples), desc="ç”Ÿæˆè¿›åº¦"):
            sample_id = i + seed_offset
            seed = sample_id + 42
            np.random.seed(seed)
            
            # 1. åŸŸéšæœºåŒ–ï¼šç”Ÿæˆéšæœºæµ“åº¦
            conc_water = np.random.uniform(0.05, 0.40)  # 5%-40% æ°´
            conc_sebum = np.random.uniform(0.05, 0.35)  # 5%-35% çš®è„‚
            conc_melanin = np.random.uniform(0.01, 0.10)  # 1%-10% é»‘è‰²ç´ 
            
            # ç¡®ä¿æ€»æµ“åº¦ <= 1.0
            total_conc = conc_water + conc_sebum + conc_melanin
            if total_conc > 1.0:
                scale = 0.95 / total_conc
                conc_water *= scale
                conc_sebum *= scale
                conc_melanin *= scale
            
            # 2. ç”Ÿæˆç©ºé—´æµ“åº¦å›¾
            map_water, map_sebum, map_melanin = self.generate_concentration_maps(
                conc_water, conc_sebum, conc_melanin, seed=seed
            )
            
            # 3. ç‰©ç†æ··åˆï¼šè®¡ç®—æœ‰æ•ˆ Î¼_a
            mu_a_map = self.compute_effective_mu_a(map_water, map_sebum, map_melanin)
            
            # 4. éšæœºæ›å…‰ + SNR å¤šæ ·æ€§
            exposure_factor = np.random.uniform(0.8, 1.2)
            
            # SNR æ¨¡å¼éšæœºé€‰æ‹© (60% high, 30% medium, 10% low)
            snr_rand = np.random.rand()
            if snr_rand < 0.6:
                snr_mode = 'high'
            elif snr_rand < 0.9:
                snr_mode = 'medium'
            else:
                snr_mode = 'low'
            
            # 5. æ­£å‘æ¨¡æ‹Ÿ
            sensor_image_adu, hypercube = self.forward_simulation(mu_a_map, exposure_factor, snr_mode)
            
            # 6. ä¿å­˜æ•°æ®
            save_path = os.path.join(self.output_dir, f"sample_{sample_id:05d}.npz")
            np.savez_compressed(
                save_path,
                x=sensor_image_adu,  # è¾“å…¥ç‰¹å¾ (uint16)
                y=np.stack([map_water, map_sebum], axis=-1),  # æ ‡ç­¾ (H, W, 2)
                meta=np.array([conc_water, conc_sebum, conc_melanin, exposure_factor])
            )
            
            # è®°å½•å…ƒæ•°æ®
            metadata_list.append({
                'sample_id': sample_id,
                'conc_water_mean': float(map_water.mean()),
                'conc_sebum_mean': float(map_sebum.mean()),
                'conc_melanin_mean': float(map_melanin.mean()),
                'exposure_factor': float(exposure_factor),
                'snr_mode': snr_mode,
                'sensor_adu_mean': float(sensor_image_adu.mean()),
                'sensor_adu_max': int(sensor_image_adu.max())
            })
        
        # ä¿å­˜å…¨å±€å…ƒæ•°æ®
        meta_path = os.path.join(self.output_dir, 'dataset_metadata.json')
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump({
                'num_samples': num_samples,
                'image_size': self.image_size,
                'num_wavelengths': self.assets.num_wavelengths,
                'wavelength_range': [float(self.assets.wavelengths[0]), float(self.assets.wavelengths[-1])],
                'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'samples': metadata_list
            }, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼ä¿å­˜è·¯å¾„: {self.output_dir}")
        print(f"  - æ ·æœ¬æ•°é‡: {num_samples}")
        print(f"  - æ–‡ä»¶å¤§å°: ~{num_samples * 0.5:.1f} MB")
    
    def visualize_sample(self, sample_id=0, save_name='step4_validation.png'):
        """
        å¯è§†åŒ–å•ä¸ªæ ·æœ¬ (éªŒè¯)
        Args:
            sample_id: æ ·æœ¬ ID
            save_name: ä¿å­˜æ–‡ä»¶å
        """
        # åŠ è½½æ ·æœ¬
        sample_path = os.path.join(self.output_dir, f"sample_{sample_id:05d}.npz")
        data = np.load(sample_path)
        
        sensor_image = data['x']
        map_water = data['y'][:, :, 0]
        map_sebum = data['y'][:, :, 1]
        meta = data['meta']
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # ä¼ æ„Ÿå™¨å›¾åƒ (è‰²æ•£æ‹–å°¾)
        im0 = axes[0].imshow(sensor_image, cmap='gray')
        axes[0].set_title(f'è¾“å…¥: ä¼ æ„Ÿå™¨å›¾åƒ (è‰²æ•£æ‹–å°¾)\nADU å‡å€¼={sensor_image.mean():.0f}', fontsize=11, fontweight='bold')
        axes[0].axis('off')
        plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)
        
        # Ground Truth: æ°´åˆ†å¸ƒ
        im1 = axes[1].imshow(map_water, cmap='Blues', vmin=0, vmax=0.5)
        axes[1].set_title(f'Ground Truth: æ°´æµ“åº¦åˆ†å¸ƒ\nå‡å€¼={map_water.mean():.3f}', fontsize=11, fontweight='bold')
        axes[1].axis('off')
        plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)
        
        # Ground Truth: çš®è„‚åˆ†å¸ƒ
        im2 = axes[2].imshow(map_sebum, cmap='Oranges', vmin=0, vmax=0.5)
        axes[2].set_title(f'Ground Truth: çš®è„‚æµ“åº¦åˆ†å¸ƒ\nå‡å€¼={map_sebum.mean():.3f}', fontsize=11, fontweight='bold')
        axes[2].axis('off')
        plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)
        
        plt.tight_layout()
        save_path = os.path.join('output', save_name)
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"\nâœ“ éªŒè¯å›¾ä¿å­˜: {save_path}")
        print(f"  - æ ·æœ¬ ID: {sample_id}")
        print(f"  - å…ƒæ•°æ®: æ°´={meta[0]:.3f}, çš®è„‚={meta[1]:.3f}, é»‘è‰²ç´ ={meta[2]:.3f}, æ›å…‰={meta[3]:.2f}")
        plt.close()


# ================================
# ä¸»ç¨‹åº
# ================================

if __name__ == "__main__":
    print("="*60)
    print("Step 4: Data Factory (Batch Generation Pipeline)")
    print("æ•°æ®å·¥å‚ï¼šæ‰¹é‡ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®é›†")
    print("="*60)
    
    # åˆå§‹åŒ–æ•°æ®å·¥å‚
    factory = DataFactory(
        assets_path='output/step1_standardized_data.csv',
        image_size=256,
        output_dir='output/datasets'
    )
    
    # ç”Ÿæˆæ•°æ®é›†
    factory.generate_batch(num_samples=100, seed_offset=0)
    
    # å¯è§†åŒ–éªŒè¯ (ç¬¬ä¸€ä¸ªæ ·æœ¬)
    factory.visualize_sample(sample_id=0, save_name='step4_validation_sample0.png')
    
    # å¯è§†åŒ–ç¬¬äºŒä¸ªæ ·æœ¬ (å¯¹æ¯”å·®å¼‚)
    factory.visualize_sample(sample_id=1, save_name='step4_validation_sample1.png')
    
    print("\n" + "="*60)
    print("âœ“ Step 4 å®Œæˆï¼")
    print("="*60)
